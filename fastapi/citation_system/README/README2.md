# ColBERT å¼•ç”¨ç”Ÿæˆç³»ç»Ÿ

åŸºäº Stanford ColBERT çš„é«˜ç²¾åº¦å¼•ç”¨ç”Ÿæˆç³»ç»Ÿï¼Œæ”¯æŒ Token çº§åŒ¹é…ã€å¯è§£é‡Šæ€§è§£é‡Šã€æ‰¹é‡å¤„ç†ç­‰åŠŸèƒ½ã€‚

## ç‰¹æ€§

- ğŸ¯ **é«˜ç²¾åº¦æ£€ç´¢**ï¼šåŸºäº ColBERT Token çº§å¯†é›†åŒ¹é…
- ğŸ” **å¯è§£é‡ŠåŒ¹é…**ï¼šToken çº§é«˜äº®å’Œä¸Šä¸‹æ–‡çª—å£
- ğŸ“Š **å®Œæ•´è¯„æµ‹**ï¼šæ”¯æŒ Precisionã€Recallã€MRRã€NDCG ç­‰æŒ‡æ ‡
- ğŸš€ **é«˜æ•ˆå¤„ç†**ï¼šæ”¯æŒæ‰¹é‡å¤„ç†å’Œå¹¶è¡ŒåŒ–
- ğŸ“ **å¤šæ ¼å¼è¾“å‡º**ï¼šMarkdownã€HTMLã€JSON æ ¼å¼
- ğŸ’¾ **æ™ºèƒ½ç¼“å­˜**ï¼šè‡ªåŠ¨ç¼“å­˜æ£€ç´¢ç»“æœ

## å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
pip install -r requirements.txt

2. å‡†å¤‡æ•°æ®
# å°†æ–‡æ¡£æ”¾å…¥ data/documents.jsonl
# æ ¼å¼ï¼š{"id": "1", "title": "æ ‡é¢˜", "text": "æ–‡æœ¬å†…å®¹"}

3. æ„å»ºç´¢å¼•
from src.indexer import DocumentLoader, ColBERTIndexer

loader = DocumentLoader()
docs = loader.load_jsonl("data/documents.jsonl")

indexer = ColBERTIndexer()
indexer.build_index(docs, force_rebuild=True)

4. ç”Ÿæˆå¼•ç”¨
from src.citation_generator import CitationGenerator

generator = CitationGenerator()
citations = generator.generate_citations("å¦‚ä½•é‡ç½®å¯†ç ", k=3)

for citation in citations:
    print(f"æ–‡æ¡£: {citation.document_id}")
    print(f"åˆ†æ•°: {citation.score:.4f}")
    print(f"é«˜äº®: {citation.highlighted_text}")

API ä½¿ç”¨
å¯åŠ¨æœåŠ¡
python app.py
å¤åˆ¶ä»£ç 
ç”Ÿæˆå¼•ç”¨
curl -X POST http://localhost:8000/cite \
  -H "Content-Type: application/json" \
  -d '{
    "query": "å¦‚ä½•é‡ç½®å¯†ç ",
    "k": 3,
    "include_explanation": true
  }'
å¤åˆ¶ä»£ç 
æ‰¹é‡å¤„ç†
curl -X POST http://localhost:8000/cite/batch \
  -H "Content-Type: application/json" \
  -d '{
    "queries": ["å¦‚ä½•é‡ç½®å¯†ç ", "API åŸºç¡€ URL"],
    "k": 3
  }'
å¤åˆ¶ä»£ç 
é«˜äº®æ–‡æ¡£
curl -X POST http://localhost:8000/highlight \
  -H "Content-Type: application/json" \
  -d '{
    "query": "é‡ç½®å¯†ç ",
    "document": "å¦‚ä½•é‡ç½®å¯†ç ï¼šè®¿é—®ç™»å½•é¡µé¢..."
  }'

è¯„æµ‹
è¿è¡Œè¯„æµ‹ï¼š

pytest tests/ -v
å¤åˆ¶ä»£ç 
è¿è¡Œæ€§èƒ½æµ‹è¯•ï¼š

pytest tests/ -v -m slow
å¤åˆ¶ä»£ç 
æ€§èƒ½æŒ‡æ ‡
æ“ä½œ	æ—¶é—´	ååé‡
æ£€ç´¢ï¼ˆTop-100ï¼‰	50-200ms	5-20 æŸ¥è¯¢/ç§’
å¼•ç”¨ç”Ÿæˆ	100-500ms	2-10 å¼•ç”¨/ç§’
é«˜äº®	10-50ms	20-100 æ–‡æ¡£/ç§’
æ‰¹é‡å¤„ç†	çº¿æ€§æ‰©å±•	æ”¯æŒå¹¶è¡ŒåŒ–
é«˜çº§ç”¨æ³•
è‡ªå®šä¹‰ç¼“å­˜
from src.cache_manager import CacheManager

cache = CacheManager(cache_dir="./cache", ttl_hours=24)

# è·å–ç¼“å­˜
result = cache.get("æŸ¥è¯¢è¯")

# è®¾ç½®ç¼“å­˜
cache.set("æŸ¥è¯¢è¯", result)

# æ¸…ç©ºç¼“å­˜
cache.clear()
å¤åˆ¶ä»£ç 
æ‰¹é‡å¤„ç†
from src.batch_processor import BatchProcessor

queries = ["æŸ¥è¯¢1", "æŸ¥è¯¢2", "æŸ¥è¯¢3"]

def process_query(q):
    return generator.generate_citations(q, k=3)

results = BatchProcessor.process_queries(
    queries,
    process_query,
    batch_size=32,
    use_parallel=True,
    max_workers=4
)
å¤åˆ¶ä»£ç 
æ€§èƒ½ç›‘æ§
from src.performance_monitor import PerformanceMonitor, TimingContext

monitor = PerformanceMonitor()

with TimingContext("æ£€ç´¢", monitor):
    results = retriever.retrieve(query)

monitor.log_summary()
å¤åˆ¶ä»£ç 
å¸¸è§é—®é¢˜
Q: ç´¢å¼•æ„å»ºéœ€è¦å¤šé•¿æ—¶é—´ï¼Ÿ
A: å–å†³äºæ–‡æ¡£æ•°é‡å’Œç¡¬ä»¶ã€‚ç™¾ä¸‡çº§æ–‡æ¡£é€šå¸¸éœ€è¦ 1-2 å°æ—¶ã€‚

Q: å¯ä»¥ä½¿ç”¨ CPU è¿è¡Œå—ï¼Ÿ
A: å¯ä»¥ï¼Œä½†ä¼šæ˜¾è‘—é™ä½é€Ÿåº¦ã€‚å»ºè®®ä½¿ç”¨ GPUã€‚

Q: æ”¯æŒä¸­æ–‡å—ï¼Ÿ
A: å®Œå…¨æ”¯æŒä¸­æ–‡ï¼ŒåŒ…æ‹¬åˆ†è¯ã€é«˜äº®ç­‰ã€‚

Q: å¦‚ä½•è‡ªå®šä¹‰æ¨¡å‹ï¼Ÿ
A: ä¿®æ”¹ config.py ä¸­çš„ COLBERT_MODEL å‚æ•°ã€‚

è®¸å¯è¯
MIT License

å¼•ç”¨
å¦‚æœä½¿ç”¨æœ¬ç³»ç»Ÿï¼Œè¯·å¼•ç”¨ï¼š

@inproceedings{khattab2021colbert,
  title={ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT},
  author={Khattab, Omar and Zaharia, Matei},
  booktitle={Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval},
  pages={39--48},
  year={2021}
}      